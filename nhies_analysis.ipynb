{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 424,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "from IPython.display import display\n",
    "\n",
    "\n",
    "# options\n",
    "pd.options.display.max_columns = None\n",
    "pd.options.display.max_rows = 1000\n",
    "sns.set(style='whitegrid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 425,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"NHIES_2015_16_household_level_labelled_TRUNC_2.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 426,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean/update labels\n",
    "# q02_58: Consumed wheat flour / bread, other cereals, rice, oils/fats\n",
    "df.loc[:,['q02_58_01']] = df.replace({'yes': 1, 'no': 0})\n",
    "df.loc[:,['q02_58_02']] = df.replace({'yes': 1, 'no': 0})\n",
    "df.loc[:,['q02_58_04']] = df.replace({'yes': 1, 'no': 0})\n",
    "df.loc[:,['q02_58_13']] = df.replace({'yes': 1, 'no': 0})\n",
    "df.loc[:,['q02_58_15']] = df.replace({'yes': 1, 'no': 0})\n",
    "\n",
    "# Clean q07_02_1-5 - replace NaN with 0; checked with 1; unchecked with 0\n",
    "cols = ['q07_02_1', 'q07_02_2', 'q07_02_3', 'q07_02_4', 'q07_02_5']\n",
    "df.loc[:,cols] = df.replace({'checked': 1, 'unchecked': 0, np.nan: 0})\n",
    "\n",
    "cols = ['q07_02_6']\n",
    "df.loc[:, cols] = df.replace({'yes': 1, 0.0: 0, '0': 0})\n",
    "\n",
    "# Clean q07_08_3 - checked with 1; unchecked with 0\n",
    "df.loc[:,['q07_08_3']] = df.replace({'checked': 1, 'unchecked': 0})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 427,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Binarize categorical variables\n",
    "\n",
    "# Clean categorical variable values\n",
    "df['q02_60_01'] = df['q02_60_01'].str.strip().str.lower().str.replace(',', '_').str.replace(' ', '_').str.replace('/', '_').str.replace('(', '').str.replace(')', '')\n",
    "df['q02_60_02'] = df['q02_60_02'].str.strip().str.lower().str.replace(',', '_').str.replace(' ', '_').str.replace('/', '_').str.replace('(', '').str.replace(')', '')\n",
    "df['q02_60_04'] = df['q02_60_04'].str.strip().str.lower().str.replace(',', '_').str.replace(' ', '_').str.replace('/', '_').str.replace('(', '').str.replace(')', '')\n",
    "df['q02_60_13'] = df['q02_60_13'].str.strip().str.lower().str.replace(',', '_').str.replace(' ', '_').str.replace('/', '_').str.replace('(', '').str.replace(')', '')\n",
    "df['q02_60_15'] = df['q02_60_15'].str.strip().str.lower().str.replace(',', '_').str.replace(' ', '_').str.replace('/', '_').str.replace('(', '').str.replace(')', '')\n",
    "\n",
    "\n",
    "# q02_60_01 -> wheat flour\n",
    "main_source_wheat_bin = pd.get_dummies(df['q02_60_01'], prefix='main_source_wheat')\n",
    "df = df[:].join(main_source_wheat_bin)\n",
    "\n",
    "# q02_60_02 -> other cereals\n",
    "main_source_other_bin = pd.get_dummies(df['q02_60_02'], prefix='main_source_other')\n",
    "df = df[:].join(main_source_other_bin)\n",
    "\n",
    "# q02_60_04 -> rice\n",
    "main_source_rice_bin = pd.get_dummies(df['q02_60_04'], prefix='main_source_rice')\n",
    "df = df[:].join(main_source_rice_bin)\n",
    "\n",
    "# q02_60_13 -> oil/fats\n",
    "main_source_oil_bin = pd.get_dummies(df['q02_60_13'], prefix='main_source_oil')\n",
    "df = df[:].join(main_source_oil_bin)\n",
    "\n",
    "# q02_60_15 -> spices\n",
    "main_source_spices_bin = pd.get_dummies(df['q02_60_15'], prefix='main_source_spices')\n",
    "df = df[:].join(main_source_spices_bin)\n",
    "\n",
    "# Replace NaN\n",
    "# Wheat flour / bread\n",
    "idx = df.columns.get_loc(\"main_source_wheat_asking_for_help_from_others\")\n",
    "cols = list(df.iloc[:,idx:(idx+11)])\n",
    "df.loc[df['q02_58_01'] == 0, cols] = np.nan\n",
    "\n",
    "# Other cereal\n",
    "idx = df.columns.get_loc(\"main_source_other_asking_for_help_from_others\")\n",
    "cols = list(df.iloc[:,idx:(idx+11)])\n",
    "df.loc[df['q02_58_02'] == 0, cols] = np.nan\n",
    "\n",
    "# Rice\n",
    "idx = df.columns.get_loc(\"main_source_rice_asking_for_help_from_others\")\n",
    "cols = list(df.iloc[:,idx:(idx+11)])\n",
    "df.loc[df['q02_58_04'] == 0, cols] = np.nan\n",
    "\n",
    "# Oils/fats\n",
    "idx = df.columns.get_loc(\"main_source_oil_asking_for_help_from_others\")\n",
    "cols = list(df.iloc[:,idx:(idx+11)])\n",
    "df.loc[df['q02_58_13'] == 0, cols] = np.nan\n",
    "\n",
    "# Spices\n",
    "idx = df.columns.get_loc(\"main_source_spices_asking_for_help_from_others\")\n",
    "cols = list(df.iloc[:,idx:(idx+11)])\n",
    "df.loc[df['q02_58_15'] == 0, cols] = np.nan\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 428,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create new variables\n",
    "\n",
    "# Age of Household Head -> Categories\n",
    "conditions = [\n",
    "    (df['age_of_head'] < 18),\n",
    "    (df['age_of_head'] >= 18) & (df['age_of_head'] < 60),\n",
    "    (df['age_of_head'] >= 60)]\n",
    "choices = ['0-18', '18-59', '60+']\n",
    "df['age_of_head_cat'] = np.select(conditions, choices)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 446,
   "metadata": {},
   "outputs": [],
   "source": [
    "# HH Consumed food group - Q02_58_01\n",
    "\n",
    "cols = ['q02_58_01', 'q02_58_02', 'q02_58_04', 'q02_58_13', 'q02_58_15']\n",
    "\n",
    "cons_yn_df = df[cols]\n",
    "\n",
    "ind_var = ['urbrur', 'region', 'sex_of_head', 'age_of_head_cat', 'attain', 'apci_dec', 'main_language', 'wgt_hh']\n",
    "ind_df = df[ind_var]\n",
    "\n",
    "cons_yn_df = pd.concat([ind_df, cons_yn_df], axis=1)\n",
    "\n",
    "# CREATE FUNCTION WHICH CALCULATES WEIGHTED AVERAGE WITH NaN DROPPED -----\n",
    "# MUST DROP NaN FROM ANALYSIS BECAUSE, IF NOT, SUM OF WEIGHTS INCREASES DENOMINATOR\n",
    "\n",
    "def group_wa10(series):\n",
    "    dropped = series.dropna()\n",
    "    try:\n",
    "        return np.average(dropped, weights = cons_yn_df.loc[dropped.index, 'wgt_hh'])\n",
    "    except ZeroDivisionError:\n",
    "        return 0\n",
    "\n",
    "# Create dictionary agg_func --> then put inside agg()\n",
    "\n",
    "agg_func11 = {'q02_58_01': [group_wa10, 'count'],\n",
    "            'q02_58_02': group_wa10,\n",
    "            'q02_58_04': group_wa10,\n",
    "            'q02_58_13': group_wa10,\n",
    "            'q02_58_15': group_wa10}\n",
    "\n",
    "obj1 = cons_yn_df.groupby('urbrur').agg(agg_func11)\n",
    "obj2 = cons_yn_df.groupby('region').agg(agg_func11)\n",
    "obj3 = cons_yn_df.groupby('sex_of_head').agg(agg_func11)\n",
    "obj4 = cons_yn_df.groupby('age_of_head_cat').agg(agg_func11)\n",
    "obj5 = cons_yn_df.groupby('attain').agg(agg_func11)\n",
    "obj6 = cons_yn_df.groupby('apci_dec').agg(agg_func11)\n",
    "obj7 = cons_yn_df.groupby('main_language').agg(agg_func11)\n",
    "\n",
    "# Stack the DataFrames on top of each other\n",
    "vertical_stack = pd.concat([obj1, obj2, obj3, obj4, obj5, obj6, obj7], axis=0)\n",
    "\n",
    "# Write DataFrame to CSV\n",
    "vertical_stack.reset_index().to_csv('q02_58_wt.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 435,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "q02_58_01    0.698104\n",
       "q02_58_02    0.819617\n",
       "q02_58_04    0.518302\n",
       "q02_58_13    0.825199\n",
       "q02_58_15    0.529356\n",
       "dtype: float64"
      ]
     },
     "execution_count": 435,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cons_yn_df.agg(agg_func11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 448,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Days Consumed food group - Q02_59_01\n",
    "\n",
    "cols = ['q02_59_01', 'q02_59_02', 'q02_59_04', 'q02_59_13', 'q02_59_15']\n",
    "\n",
    "cons_days_df = df[cols]\n",
    "\n",
    "ind_var = ['urbrur', 'region', 'sex_of_head', 'age_of_head_cat', 'attain', 'apci_dec', 'main_language', 'wgt_hh']\n",
    "ind_df = df[ind_var]\n",
    "\n",
    "cons_days_df = pd.concat([ind_df, cons_days_df], axis=1)\n",
    "\n",
    "# CREATE FUNCTION WHICH CALCULATES WEIGHTED AVERAGE WITH NaN DROPPED -----\n",
    "# MUST DROP NaN FROM ANALYSIS BECAUSE, IF NOT, SUM OF WEIGHTS INCREASES DENOMINATOR\n",
    "\n",
    "def group_wa11(series):\n",
    "    dropped = series.dropna()\n",
    "    try:\n",
    "        return np.average(dropped, weights = cons_days_df.loc[dropped.index, 'wgt_hh'])\n",
    "    except ZeroDivisionError:\n",
    "        return 0\n",
    "\n",
    "# Create dictionary agg_func --> then put inside agg()\n",
    "\n",
    "agg_func12 = {'q02_59_01': [group_wa11, 'count'],\n",
    "            'q02_59_02': [group_wa11, 'count'],\n",
    "            'q02_59_04': [group_wa11, 'count'],\n",
    "            'q02_59_13': [group_wa11, 'count'],\n",
    "            'q02_59_15': [group_wa11, 'count']}\n",
    "\n",
    "obj1 = cons_days_df.groupby('urbrur').agg(agg_func12)\n",
    "obj2 = cons_days_df.groupby('region').agg(agg_func12)\n",
    "obj3 = cons_days_df.groupby('sex_of_head').agg(agg_func12)\n",
    "obj4 = cons_days_df.groupby('age_of_head_cat').agg(agg_func12)\n",
    "obj5 = cons_days_df.groupby('attain').agg(agg_func12)\n",
    "obj6 = cons_days_df.groupby('apci_dec').agg(agg_func12)\n",
    "obj7 = cons_days_df.groupby('main_language').agg(agg_func12)\n",
    "\n",
    "# Stack the DataFrames on top of each other\n",
    "vertical_stack = pd.concat([obj1, obj2, obj3, obj4, obj5, obj6, obj7], axis=0)\n",
    "\n",
    "# Write DataFrame to CSV\n",
    "vertical_stack.reset_index().to_csv('q02_59_wt.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 437,
   "metadata": {},
   "outputs": [],
   "source": [
    "### --------  Q02_60\n",
    "\n",
    "# ------------  Create reduced dataframe -----------------\n",
    "\n",
    "idx = df.columns.get_loc(\"main_source_wheat_asking_for_help_from_others\")\n",
    "cols = list(df.iloc[:,idx:(idx+54)])\n",
    "\n",
    "staple_source_df = df[cols]\n",
    "\n",
    "ind_var = ['urbrur', 'region', 'sex_of_head', 'age_of_head_cat', 'attain', 'apci_dec', 'main_language', 'wgt_hh']\n",
    "ind_df = df[ind_var]\n",
    "\n",
    "staple_source_df = pd.concat([ind_df, staple_source_df], axis=1)\n",
    "\n",
    "# CREATE FUNCTION WHICH CALCULATES WEIGHTED AVERAGE WITH NaN DROPPED -----\n",
    "# MUST DROP NaN FROM ANALYSIS BECAUSE, IF NOT, SUM OF WEIGHTS INCREASES DENOMINATOR\n",
    "\n",
    "def group_wa(series):\n",
    "    dropped = series.dropna()\n",
    "    try:\n",
    "        return np.average(dropped, weights=staple_source_df.loc[dropped.index, 'wgt_hh'])\n",
    "    except ZeroDivisionError:\n",
    "        return 0\n",
    "\n",
    "# Create dictionary agg_func using dict comprehension --> then put inside agg()\n",
    "\n",
    "agg_func1 = {cols[i]: group_wa for i in range(len(cols))}\n",
    "\n",
    "obj1 = staple_source_df.groupby('urbrur').agg(agg_func1)\n",
    "obj2 = staple_source_df.groupby('region').agg(agg_func1)\n",
    "obj3 = staple_source_df.groupby('sex_of_head').agg(agg_func1)\n",
    "obj4 = staple_source_df.groupby('age_of_head_cat').agg(agg_func1)\n",
    "obj5 = staple_source_df.groupby('attain').agg(agg_func1)\n",
    "obj6 = staple_source_df.groupby('apci_dec').agg(agg_func1)\n",
    "obj7 = staple_source_df.groupby('main_language').agg(agg_func1)\n",
    "\n",
    "# Stack the DataFrames on top of each other\n",
    "vertical_stack = pd.concat([obj1, obj2, obj3, obj4, obj5, obj6, obj7], axis=0)\n",
    "\n",
    "# Write DataFrame to CSV\n",
    "vertical_stack.reset_index().to_csv('q02_60_wt.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 449,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = ['q07_02_1', 'q07_02_2', 'q07_02_3', 'q07_02_4', 'q07_02_6']\n",
    "\n",
    "grow_yn_df = df[cols]\n",
    "\n",
    "ind_var = ['urbrur', 'region', 'sex_of_head', 'age_of_head_cat', 'attain', 'apci_dec', 'main_language', 'wgt_hh']\n",
    "ind_df = df[ind_var]\n",
    "\n",
    "grow_yn_df = pd.concat([ind_df, grow_yn_df], axis=1)\n",
    "\n",
    "# CREATE FUNCTION WHICH CALCULATES WEIGHTED AVERAGE WITH NaN DROPPED -----\n",
    "# MUST DROP NaN FROM ANALYSIS BECAUSE, IF NOT, SUM OF WEIGHTS INCREASES DENOMINATOR\n",
    "\n",
    "def group_wa7(series):\n",
    "    dropped = series.dropna()\n",
    "    try:\n",
    "        return np.average(dropped, weights = grow_yn_df.loc[dropped.index, 'wgt_hh'])\n",
    "    except ZeroDivisionError:\n",
    "        return 0\n",
    "\n",
    "# Create dictionary agg_func --> then put inside agg()\n",
    "\n",
    "agg_func8 = {'q07_02_1': [group_wa6, 'count'],\n",
    "            'q07_02_2': [group_wa6, 'count'],\n",
    "            'q07_02_3': [group_wa6, 'count'],\n",
    "            'q07_02_4': [group_wa6, 'count'],\n",
    "            'q07_02_6': [group_wa6, 'count']}\n",
    "\n",
    "obj1 = grow_yn_df.groupby('urbrur').agg(agg_func8)\n",
    "obj2 = grow_yn_df.groupby('region').agg(agg_func8)\n",
    "obj3 = grow_yn_df.groupby('sex_of_head').agg(agg_func8)\n",
    "obj4 = grow_yn_df.groupby('age_of_head_cat').agg(agg_func8)\n",
    "obj5 = grow_yn_df.groupby('attain').agg(agg_func8)\n",
    "obj6 = grow_yn_df.groupby('apci_dec').agg(agg_func8)\n",
    "obj7 = grow_yn_df.groupby('main_language').agg(agg_func8)\n",
    "\n",
    "# Stack the DataFrames on top of each other\n",
    "vertical_stack = pd.concat([obj1, obj2, obj3, obj4, obj5, obj6, obj7], axis=0)\n",
    "\n",
    "# Write DataFrame to CSV\n",
    "vertical_stack.reset_index().to_csv('q07_02_1-6_wt.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 439,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Amount of crop grown - 'crops_possessed*'\n",
    "\n",
    "# ------------  Create reduced dataframe -----------------\n",
    "\n",
    "cols = list(['crops_possessed_1', 'crops_possessed_2','crops_possessed_3', 'crops_possessed_4', 'crops_possessed_6'])\n",
    "\n",
    "amount_df = df[cols]\n",
    "amount_df = amount_df.astype('float64')\n",
    "\n",
    "ind_var = ['urbrur', 'region', 'sex_of_head', 'age_of_head_cat', 'attain', 'apci_dec', 'main_language', 'wgt_hh']\n",
    "ind_df = df[ind_var]\n",
    "\n",
    "amount_df = pd.concat([ind_df, amount_df], axis=1)\n",
    "\n",
    "# CREATE FUNCTION WHICH CALCULATES WEIGHTED AVERAGE WITH NaN DROPPED -----\n",
    "# MUST DROP NaN FROM ANALYSIS BECAUSE, IF NOT, SUM OF WEIGHTS INCREASES DENOMINATOR\n",
    "\n",
    "def group_wa1(series):\n",
    "    dropped = series.dropna()\n",
    "    try:\n",
    "        return np.average(dropped, weights=amount_df.loc[dropped.index, 'wgt_hh'])\n",
    "    except ZeroDivisionError:\n",
    "        return 0\n",
    "\n",
    "# Create dictionary agg_func using dict comprehension --> then put inside agg()\n",
    "\n",
    "#agg_func2 = {cols[i]: group_wa1 for i in range(len(cols))}\n",
    "\n",
    "agg_func2 = {'crops_possessed_1': group_wa1,\n",
    "            'crops_possessed_2': group_wa1,\n",
    "            'crops_possessed_3': group_wa1,\n",
    "            'crops_possessed_4': group_wa1,\n",
    "            'crops_possessed_6': group_wa1}\n",
    "\n",
    "obj1 = amount_df.groupby('urbrur').agg(agg_func2)\n",
    "obj2 = amount_df.groupby('region').agg(agg_func2)\n",
    "obj3 = amount_df.groupby('sex_of_head').agg(agg_func2)\n",
    "obj4 = amount_df.groupby('age_of_head_cat').agg(agg_func2)\n",
    "obj5 = amount_df.groupby('attain').agg(agg_func2)\n",
    "obj6 = amount_df.groupby('apci_dec').agg(agg_func2)\n",
    "obj7 = amount_df.groupby('main_language').agg(agg_func2)\n",
    "\n",
    "# Stack the DataFrames on top of each other\n",
    "vertical_stack = pd.concat([obj1, obj2, obj3, obj4, obj5, obj6, obj7], axis=0)\n",
    "\n",
    "# Write DataFrame to CSV\n",
    "vertical_stack.reset_index().to_csv('q07_03_wt.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 450,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Amount of crop consumed - q07_04_1\n",
    "\n",
    "# ------------  Create reduced dataframe -----------------\n",
    "\n",
    "cols = list(['q07_04_1', 'q07_04_2','q07_04_3', 'q07_04_4', 'q07_04_6'])\n",
    "\n",
    "amount_cons_df = df[cols]\n",
    "#amount_cons_df = amount_df.astype('float64')\n",
    "\n",
    "ind_var = ['urbrur', 'region', 'sex_of_head', 'age_of_head_cat', 'attain', 'apci_dec', 'main_language', 'wgt_hh']\n",
    "ind_df = df[ind_var]\n",
    "\n",
    "amount_cons_df = pd.concat([ind_df, amount_cons_df], axis=1)\n",
    "\n",
    "# CREATE FUNCTION WHICH CALCULATES WEIGHTED AVERAGE WITH NaN DROPPED -----\n",
    "# MUST DROP NaN FROM ANALYSIS BECAUSE, IF NOT, SUM OF WEIGHTS INCREASES DENOMINATOR\n",
    "\n",
    "def group_wa2(series):\n",
    "    dropped = series.dropna()\n",
    "    try:\n",
    "        return np.average(dropped, weights = amount_cons_df.loc[dropped.index, 'wgt_hh'])\n",
    "    except ZeroDivisionError:\n",
    "        return 0\n",
    "\n",
    "# Create dictionary agg_func using dict comprehension --> then put inside agg()\n",
    "\n",
    "#agg_func2 = {cols[i]: group_wa1 for i in range(len(cols))}\n",
    "\n",
    "agg_func3 = {'q07_04_1': [group_wa2, 'count'],\n",
    "            'q07_04_2': [group_wa2, 'count'],\n",
    "            'q07_04_3': [group_wa2, 'count'],\n",
    "            'q07_04_4': [group_wa2, 'count'],\n",
    "            'q07_04_6': [group_wa2, 'count']}\n",
    "\n",
    "obj1 = amount_cons_df.groupby('urbrur').agg(agg_func3)\n",
    "obj2 = amount_cons_df.groupby('region').agg(agg_func3)\n",
    "obj3 = amount_cons_df.groupby('sex_of_head').agg(agg_func3)\n",
    "obj4 = amount_cons_df.groupby('age_of_head_cat').agg(agg_func3)\n",
    "obj5 = amount_cons_df.groupby('attain').agg(agg_func3)\n",
    "obj6 = amount_cons_df.groupby('apci_dec').agg(agg_func3)\n",
    "obj7 = amount_cons_df.groupby('main_language').agg(agg_func3)\n",
    "\n",
    "# Stack the DataFrames on top of each other\n",
    "vertical_stack = pd.concat([obj1, obj2, obj3, obj4, obj5, obj6, obj7], axis=0)\n",
    "\n",
    "# Write DataFrame to CSV\n",
    "vertical_stack.reset_index().to_csv('q07_04_wt.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 441,
   "metadata": {},
   "outputs": [],
   "source": [
    "# How much of crop grown was given away\n",
    "cols = ['crops_given_away_1', 'crops_given_away_2', 'crops_given_away_3', 'crops_given_away_4', 'crops_given_away_6']\n",
    "\n",
    "amount_give_df = df[cols]\n",
    "#amount_cons_df = amount_df.astype('float64')\n",
    "\n",
    "ind_var = ['urbrur', 'region', 'sex_of_head', 'age_of_head_cat', 'attain', 'apci_dec', 'main_language', 'wgt_hh']\n",
    "ind_df = df[ind_var]\n",
    "\n",
    "amount_give_df = pd.concat([ind_df, amount_give_df], axis=1)\n",
    "\n",
    "# CREATE FUNCTION WHICH CALCULATES WEIGHTED AVERAGE WITH NaN DROPPED -----\n",
    "# MUST DROP NaN FROM ANALYSIS BECAUSE, IF NOT, SUM OF WEIGHTS INCREASES DENOMINATOR\n",
    "\n",
    "def group_wa3(series):\n",
    "    dropped = series.dropna()\n",
    "    try:\n",
    "        return np.average(dropped, weights = amount_give_df.loc[dropped.index, 'wgt_hh'])\n",
    "    except ZeroDivisionError:\n",
    "        return 0\n",
    "\n",
    "# Create dictionary agg_func using dict comprehension --> then put inside agg()\n",
    "\n",
    "#agg_func2 = {cols[i]: group_wa1 for i in range(len(cols))}\n",
    "\n",
    "agg_func4 = {'crops_given_away_1': group_wa3,\n",
    "            'crops_given_away_2': group_wa3,\n",
    "            'crops_given_away_3': group_wa3,\n",
    "            'crops_given_away_4': group_wa3,\n",
    "            'crops_given_away_6': group_wa3}\n",
    "\n",
    "obj1 = amount_give_df.groupby('urbrur').agg(agg_func4)\n",
    "obj2 = amount_give_df.groupby('region').agg(agg_func4)\n",
    "obj3 = amount_give_df.groupby('sex_of_head').agg(agg_func4)\n",
    "obj4 = amount_give_df.groupby('age_of_head_cat').agg(agg_func4)\n",
    "obj5 = amount_give_df.groupby('attain').agg(agg_func4)\n",
    "obj6 = amount_give_df.groupby('apci_dec').agg(agg_func4)\n",
    "obj7 = amount_give_df.groupby('main_language').agg(agg_func4)\n",
    "\n",
    "# Stack the DataFrames on top of each other\n",
    "vertical_stack = pd.concat([obj1, obj2, obj3, obj4, obj5, obj6, obj7], axis=0)\n",
    "\n",
    "# Write DataFrame to CSV\n",
    "vertical_stack.reset_index().to_csv('q07_05_wt.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 442,
   "metadata": {},
   "outputs": [],
   "source": [
    "# How much of crop grown was sold\n",
    "cols = ['crops_sold_1', 'crops_sold_2', 'crops_sold_3', 'crops_sold_4', 'crops_sold_6']\n",
    "\n",
    "amount_sold_df = df[cols]\n",
    "\n",
    "ind_var = ['urbrur', 'region', 'sex_of_head', 'age_of_head_cat', 'attain', 'apci_dec', 'main_language', 'wgt_hh']\n",
    "ind_df = df[ind_var]\n",
    "\n",
    "amount_sold_df = pd.concat([ind_df, amount_sold_df], axis=1)\n",
    "\n",
    "# CREATE FUNCTION WHICH CALCULATES WEIGHTED AVERAGE WITH NaN DROPPED -----\n",
    "# MUST DROP NaN FROM ANALYSIS BECAUSE, IF NOT, SUM OF WEIGHTS INCREASES DENOMINATOR\n",
    "\n",
    "def group_wa4(series):\n",
    "    dropped = series.dropna()\n",
    "    try:\n",
    "        return np.average(dropped, weights = amount_sold_df.loc[dropped.index, 'wgt_hh'])\n",
    "    except ZeroDivisionError:\n",
    "        return 0\n",
    "\n",
    "# Create dictionary agg_func using dict comprehension --> then put inside agg()\n",
    "\n",
    "#agg_func2 = {cols[i]: group_wa1 for i in range(len(cols))}\n",
    "\n",
    "agg_func5 = {'crops_sold_1': group_wa4,\n",
    "            'crops_sold_2': group_wa4,\n",
    "            'crops_sold_3': group_wa4,\n",
    "            'crops_sold_4': group_wa4,\n",
    "            'crops_sold_6': group_wa4}\n",
    "\n",
    "obj1 = amount_sold_df.groupby('urbrur').agg(agg_func5)\n",
    "obj2 = amount_sold_df.groupby('region').agg(agg_func5)\n",
    "obj3 = amount_sold_df.groupby('sex_of_head').agg(agg_func5)\n",
    "obj4 = amount_sold_df.groupby('age_of_head_cat').agg(agg_func5)\n",
    "obj5 = amount_sold_df.groupby('attain').agg(agg_func5)\n",
    "obj6 = amount_sold_df.groupby('apci_dec').agg(agg_func5)\n",
    "obj7 = amount_sold_df.groupby('main_language').agg(agg_func5)\n",
    "\n",
    "# Stack the DataFrames on top of each other\n",
    "vertical_stack = pd.concat([obj1, obj2, obj3, obj4, obj5, obj6, obj7], axis=0)\n",
    "\n",
    "# Write DataFrame to CSV\n",
    "vertical_stack.reset_index().to_csv('q07_06_wt.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 443,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Of crop grown that was sold, avg price/kg (mean, $N/kg)\n",
    "\n",
    "#create $N/kg variable\n",
    "df['crops_sales_value_1'] = df['crops_sales_value_1'] / df['crops_sold_1']\n",
    "df['crops_sales_value_2'] = df['crops_sales_value_2'] / df['crops_sold_2']\n",
    "\n",
    "cols = ['crops_sales_value_1', 'crops_sales_value_2']\n",
    "\n",
    "value_sold_df = df[cols]\n",
    "\n",
    "ind_var = ['urbrur', 'region', 'sex_of_head', 'age_of_head_cat', 'attain', 'apci_dec', 'main_language', 'wgt_hh']\n",
    "ind_df = df[ind_var]\n",
    "\n",
    "value_sold_df = pd.concat([ind_df, value_sold_df], axis=1)\n",
    "\n",
    "# CREATE FUNCTION WHICH CALCULATES WEIGHTED AVERAGE WITH NaN DROPPED -----\n",
    "# MUST DROP NaN FROM ANALYSIS BECAUSE, IF NOT, SUM OF WEIGHTS INCREASES DENOMINATOR\n",
    "\n",
    "def group_wa5(series):\n",
    "    dropped = series.dropna()\n",
    "    try:\n",
    "        return np.average(dropped, weights = value_sold_df.loc[dropped.index, 'wgt_hh'])\n",
    "    except ZeroDivisionError:\n",
    "        return 0\n",
    "\n",
    "# Create dictionary agg_func using dict comprehension --> then put inside agg()\n",
    "\n",
    "#agg_func2 = {cols[i]: group_wa1 for i in range(len(cols))}\n",
    "\n",
    "agg_func6 = {'crops_sales_value_1': group_wa5,\n",
    "            'crops_sales_value_2': group_wa5}\n",
    "\n",
    "obj1 = value_sold_df.groupby('urbrur').agg(agg_func6)\n",
    "obj2 = value_sold_df.groupby('region').agg(agg_func6)\n",
    "obj3 = value_sold_df.groupby('sex_of_head').agg(agg_func6)\n",
    "obj4 = value_sold_df.groupby('age_of_head_cat').agg(agg_func6)\n",
    "obj5 = value_sold_df.groupby('attain').agg(agg_func6)\n",
    "obj6 = value_sold_df.groupby('apci_dec').agg(agg_func6)\n",
    "obj7 = value_sold_df.groupby('main_language').agg(agg_func6)\n",
    "\n",
    "# Stack the DataFrames on top of each other\n",
    "vertical_stack = pd.concat([obj1, obj2, obj3, obj4, obj5, obj6, obj7], axis=0)\n",
    "\n",
    "# Write DataFrame to CSV\n",
    "vertical_stack.reset_index().to_csv('q07_07_wt.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 444,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Produce butter/oils/fats - q07_08_3\n",
    "\n",
    "cols = ['q07_08_3']\n",
    "\n",
    "butter_df = df[cols]\n",
    "\n",
    "ind_var = ['urbrur', 'region', 'sex_of_head', 'age_of_head_cat', 'attain', 'apci_dec', 'main_language', 'wgt_hh']\n",
    "ind_df = df[ind_var]\n",
    "\n",
    "butter_df = pd.concat([ind_df, butter_df], axis=1)\n",
    "\n",
    "# CREATE FUNCTION WHICH CALCULATES WEIGHTED AVERAGE WITH NaN DROPPED -----\n",
    "# MUST DROP NaN FROM ANALYSIS BECAUSE, IF NOT, SUM OF WEIGHTS INCREASES DENOMINATOR\n",
    "\n",
    "def group_wa6(series):\n",
    "    dropped = series.dropna()\n",
    "    try:\n",
    "        return np.average(dropped, weights = butter_df.loc[dropped.index, 'wgt_hh'])\n",
    "    except ZeroDivisionError:\n",
    "        return 0\n",
    "\n",
    "# Create dictionary agg_func --> then put inside agg()\n",
    "\n",
    "agg_func7 = {'q07_08_3': group_wa6}\n",
    "\n",
    "obj1 = butter_df.groupby('urbrur').agg(agg_func7)\n",
    "obj2 = butter_df.groupby('region').agg(agg_func7)\n",
    "obj3 = butter_df.groupby('sex_of_head').agg(agg_func7)\n",
    "obj4 = butter_df.groupby('age_of_head_cat').agg(agg_func7)\n",
    "obj5 = butter_df.groupby('attain').agg(agg_func7)\n",
    "obj6 = butter_df.groupby('apci_dec').agg(agg_func7)\n",
    "obj7 = butter_df.groupby('main_language').agg(agg_func7)\n",
    "\n",
    "# Stack the DataFrames on top of each other\n",
    "vertical_stack = pd.concat([obj1, obj2, obj3, obj4, obj5, obj6, obj7], axis=0)\n",
    "\n",
    "# Write DataFrame to CSV\n",
    "vertical_stack.reset_index().to_csv('q07_08_3_wt.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "EXTRA TO DELETE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# USEFUL CODE\n",
    "#output_names = []\n",
    "#output_names.extend([v for k,v in locals().items() if k.startswith('o_')])\n",
    "    \n",
    "#frame = {cols[i]: output_names[i] for i in range(len(output_names))} "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grow crop\n",
    "#grow_crop_urban = df.loc[:,'q07_02_1':'q07_02_6'].groupby(df['urban']).agg(['mean'])\n",
    "#grow_crop_region = df.loc[:,'q07_02_1':'q07_02_6'].groupby(df['region']).agg(['mean'])\n",
    "#grow_crop_sex = df.loc[:,'q07_02_1':'q07_02_6'].groupby(df['sex_of_head']).agg(['mean'])\n",
    "#grow_crop_age = df.loc[:,'q07_02_1':'q07_02_6'].groupby(df['age_of_head_cat']).agg(['mean'])\n",
    "#grow_crop_attain = df.loc[:,'q07_02_1':'q07_02_6'].groupby(df['attain']).agg(['mean'])\n",
    "#grow_crop_income = df.loc[:,'q07_02_1':'q07_02_6'].groupby(df['apci_dec']).agg(['mean'])\n",
    "#grow_crop_language = df.loc[:,'q07_02_1':'q07_02_6'].groupby(df['main_language']).agg(['mean'])\n",
    "\n",
    "# Stack the DataFrames on top of each other\n",
    "#vertical_stack = pd.concat([grow_crop_urban, grow_crop_region, grow_crop_sex, grow_crop_age, grow_crop_attain, grow_crop_income, grow_crop_language], axis=0)\n",
    "\n",
    "# Write DataFrame to CSV\n",
    "#vertical_stack.reset_index().to_csv('q07_02_1-6.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# q_07_03 How much of crop grown (kgs)\n",
    "#cols = ['crops_possessed_1', 'crops_possessed_2', 'crops_possessed_3', 'crops_possessed_4', 'crops_possessed_5', 'crops_possessed_6']\n",
    "\n",
    "#grow_crop_amount_urban = df.loc[:,cols].groupby(df['urban']).agg(['mean', 'sum'])\n",
    "#grow_crop_amount_region = df.loc[:,cols].groupby(df['region']).agg(['mean', 'sum'])\n",
    "#grow_crop_amount_sex = df.loc[:,cols].groupby(df['sex_of_head']).agg(['mean', 'sum'])\n",
    "#grow_crop_amount_age = df.loc[:,cols].groupby(df['age_of_head_cat']).agg(['mean', 'sum'])\n",
    "#grow_crop_amount_attain = df.loc[:,cols].groupby(df['attain']).agg(['mean', 'sum'])\n",
    "#grow_crop_amount_income = df.loc[:,cols].groupby(df['apci_dec']).agg(['mean', 'sum'])\n",
    "#grow_crop_amount_language = df.loc[:,cols].groupby(df['main_language']).agg(['mean', 'sum'])\n",
    "\n",
    "# Stack the DataFrames on top of each other\n",
    "#vertical_stack = pd.concat([grow_crop_amount_urban, grow_crop_amount_region, grow_crop_amount_sex, grow_crop_amount_age, grow_crop_amount_attain, grow_crop_amount_income, grow_crop_amount_language], axis=0)\n",
    "\n",
    "# Write DataFrame to CSV\n",
    "#vertical_stack.reset_index().to_csv('q07_03.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 410,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Consumption on Food\n",
    "#food_cons_urban = df.loc[:,'g01_food_capita'].groupby(df['urban']).agg(['mean', 'median', 'count'])\n",
    "#food_cons_region = df.loc[:,'g01_food_capita'].groupby(df['region']).agg(['mean', 'median', 'count'])\n",
    "#food_cons_sex = df.loc[:,'g01_food_capita'].groupby(df['sex_of_head']).agg(['mean', 'median', 'count'])\n",
    "#food_cons_age = df.loc[:,'g01_food_capita'].groupby(df['age_of_head_cat']).agg(['mean', 'median', 'count'])\n",
    "#food_cons_attain = df.loc[:,'g01_food_capita'].groupby(df['attain']).agg(['mean', 'median', 'count'])\n",
    "#food_cons_income = df.loc[:,'g01_food_capita'].groupby(df['apci_dec']).agg(['mean', 'median', 'count'])\n",
    "#food_cons_language = df.loc[:,'g01_food_capita'].groupby(df['main_language']).agg(['mean', 'median', 'count'])\n",
    "\n",
    "# Stack the DataFrames on top of each other\n",
    "#vertical_stack = pd.concat([food_cons_urban, food_cons_region, food_cons_sex, food_cons_age, food_cons_attain, food_cons_income, food_cons_language], axis=0)\n",
    "\n",
    "# Write DataFrame to CSV\n",
    "#vertical_stack.reset_index().to_csv('g01_food.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
